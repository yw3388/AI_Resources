##cpu
https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel

cpu/cuda: conda install numba cudatoolkit pyculib

## from stackoverflow
RuntimeError: size mismatch, m1: [a x b], m2: [c x d]
all you have to care is b=c and you are done:

m1 is [a x b] which is [batch size x in features]

m2 is [c x d] which is [in features x out features]
https://pytorch.org/docs/master/generated/torch.nn.Linear.html#torch.nn.Linear


ValueError: attempted relative import beyond top-level package


##from website
class construction
assignment perfom on variables, objects in memory
function calls return objects

self.hunger = hunger
self.get_hunger(): return self.hunger

constructor: 
constructor overloading:
no parameter is no parameter
this.n = N(parameter)

this in front of the field name: this.number is not necessary. 

##cnn
convnet: width, height, depth
every layer has a simple api

##convolutional layer, pooling layer, fully-connected layer
INPUT: width, height, three channels
CONV: weight, regions connected to input, filters
relu: activation max(0, x)
pool: width, height
fc: fully connected layer


https://www.youtube.com/watch?v=Li5sVEXTIJw

Activation: gate to activate or not
softmax: to proba, then choose max to give output

Feed forward neural network--一种归一化

结构性数据与非结构性数据
convolution: 
a, b, 1
就view改成b， a， -1


torch.nn is nn.Module
apply fn recursively to every submodule
buffers: recurse is True


for name, buf in self.named_buffers():
  if name in ['running_var']:
  print(buf.size())
  
 for name, module in model.named_children():
    if name in ['conv4']:
      print(module)
      
  for name, param in named_parameters():
    if name in ['bias']:
        param.size()
        
        
        
        
###webscrapping and downloading data
Your bottleneck is probably that you write the file to disk first and then read it again (I/O). 
If the file does not exceed your machines random access memory, decompressing the file on the fly in memory might be a faster option
json.gzip



decompression from gzip pkg

read_csv(compression = 'gzip')


###decode, Stringio
Bytes flow:

.json() easy

shrimpy

##pandas.read_clipboard(sep='\\s+', **kwargs)[source]
Read text from clipboard and pass to read_csv.

Parameters
sepstr, default ‘s+’
A string or regex delimiter. The default of ‘s+’ denotes one or more whitespace characters.

**kwargs
See read_csv for the full argument list.

Returns
DataFrame
A parsed DataFrame object.


###DL
https://www.kaggle.com/kanncaa1/deep-learning-tutorial-for-beginners
https://www.kaggle.com/kanncaa1/pytorch-tutorial-for-deep-learning-lovers
https://www.kaggle.com/arunkumarramanan/awesome-deep-learning-with-cnn-mnist-classifier
https://github.com/yw3388/awesome-deeplearning-resources

Blogs: 


/[+-]?\d+/ integers
/[+-]?\d+\./ 1., 321.
/[+-]?\.\d+/ .1, .234
/[+-]?\d+\.\d+/ 1.0

/[+-]?(\d+\.\d+|\d+\./
|\.\d+)/


find floats and integers in string
'\d*\.?\d+'


##@property
getter and setter:
add constraints in setters

makes a property object temperature. 
Simply put, property attaches some code to the member attribute accesses.
In Python, property() is a built-in function that creates and returns a property object. 
A property object has three methods, getter(), setter(), and deleter() 


define:
t = property(get_method, set_method)
any method call t will call get_method
any method assign value to t will call set_method
get and set: change attributes as self.__attribute

为什么用properties
所有属性在Python中都是公共的。以下划线或两个下划线开头的名称只是一个警告，即给定的属性是一个实现细

@property
@p.setter
getter and setter hide in attributes


属性的缺点：
很难处理异常值
比如我刚刚想pass parameters到一个setter中
但是error了
就会报错：recursion error， exceed number 
非常无益的回溯(

好处：
项目小的时候不想改变端口，仅仅数据改变，
只需要call类的成员即可，直接成员访问
用property改一些属性（pass parameter）

可以pythonic用来装逼



__method__: you don't use it
def __method(self): __避免被subclass overridden
_: 单行线is a property, and it's part of the API,


##liNUX
vim test.html
$pwd
$cd
$cd ..
$ls -la
$ mkdir create new directory
$cat : output the contents of file
$ rm <file>
$ rm -r <directory>
$mv <file><filenew>
$cp <file> <directory>: copy file to existing files ocerwriting an file
$cp -r <directory><directory2>
$ touch file: udpate file access and modification time 
$ chmod -R 600 <directory>
change permission to 600
$ find <dir> -name "<file>"
'*'


###When I find there are wheels and packages already on github, my time and work is like a bunch of shit, yea...(
git push 
git pull
git checkout -b "new-branch"
git add
git commit -m 
git commit -a
git push origin master (changed??)
git checkout -b <branchname>


##arguments and parameters
improt argparse
 parser = argparse.ArgumentParser()
 parser.add_argument('ech')
 parser.parse_args()


parser = argparse.ArgumentParser()
groupgroup = parser.add_mutually_exclustive_group()
group.add_argument('-v', '--versbose')
group.add_argument('-q', '--quiet')
parser.add_argument('x', type = int, help = 'the base')
parser.add_argument('y', type = int, help = 'the exponent')
args = parser.parse_args()
answer = args.x * args.y

if args.quiet:
    print (answer)
    
    
   [-h][-v|-q] xy
   
   
 ##叫parse的inner function是什么developer的命名标准吗
 ##叫parse的inner function是什么developer的命名标准吗
 害得我研究半天parser和wrapper as decorator

decorator
No.1
@decorator
class a:
     blablabla
insr = a(50)
No.2
a = decorator(a)
insr = a(50)


修饰器就是把class和另一个class wrapper bind起来
parameter是cls或者function（well python觉得世界全都是objects）
wrapper保护了enclosed class 又embed了instance（wrap）
可以帮助想改变世界的人给新的cls加更多的功能性又保护了封装的原来的世界



list = [1, 2, 4]
例子是计算count次数
def count（func）：
    def inner(*args, **kwargs):
    #functions' running times
      count = list[-1]
      func(*args, **kwargs)
      count -= 1
      return count
     return inner
 @count
 def sum(num):
    return math.sum(num)
 
 
 print(sum([1, 10]))
 
output: 
 11
 3
 
 
 This instance is like 省下力气？
 
 def do_twice(func):
    def wrapper_do_twice():
        func()
        func()
    return wrapper_do_twice
    
    
from module import do_twice
 
@do_twice
def loss_weight():
    print("瘦了!")
    
    
    
loss_weight()
瘦了！
瘦了！

static method:
bound to class but not objects
do not require class instance
knows nothing abou class deals with prameters
does not access class peorperties but belongs o the class
比图另外创建一个object update value但是不用class里的
parameters


inheritance
很好的运用了static method要是子类不改变父类
parameters

####
bug in *args, **kwargs
class pass in **kwargs to __init__, error in passing one parameter but take no parameter
kwarg is okay
*kwarg is pass in tuples
setattr(): three arguments

vars(class object) to get all attrs
some_func(fargs, *args, **kwargs)

##为啥子用
因为猴子补丁，runtime时候可以改变值
官方给的例子非常适用

a function called get_info which calls an API and returns the response data. 
If we want to test it we can replace the API call with some test data. For instance:

import someclass

def get_info(self, *args):
    return "Test data"

someclass.get_info = get_info


##modules
The dir() built-in function returns a sorted list of strings containing the names defined by a module.
date.fromtimestamp()


#an interesting one for reddit wrapper
PRAW
reddit = praw.Reddit() 


after import, do not want to open source codes in a different directory（懒）
##inspect
inspect.getmembers(sample)
print(inspect.getsource(module.method))
inspect.signature(module.method) ##need what parameters

##generator
If the list is smaller than the running machine’s available memory, 
then list comprehensions can be faster to evaluate than the equivalent generator expression. 
.send()
handle exceptions with .throw() 
stop the generator after a given amount of digits with .close()



for i in generator:
  generator.send(##)
  
  send ## to the generator
  
  
  ##above is coroutine 
  
  ##.throw() allows you to throw exceptions with the generator  
  except stopIteratino
  
  
if sth:
    generator.throw(ValueError)
    
   ##.close() is that it raises StopIteration, an exception used to signal the end of a finite iterator
   
   ##no change in parameter in generator
   ##solution: yield (parameter) after updates
   
   ##timestamp todatetime
   date_time_obj = date.to_pydatetime()
   datetime.timestamp() ## in seconds, not in milliseconds
   
   
import socket
s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
s.connect(("8.8.8.8", 80))
print(s.getsockname()[0])
s.close()   
   
   
   
npm dedupe

##Threading
i/o tasks
cpython: global interpreter lock, only one thread can execute python coe
threading.enumerate(): return a list of Thread objects alive
threading.Event(): a new event object


threading.Thread(group, target, name, args = (), kwargs = ())
group should be None
target: invoked by run()
name : thread name
args = argument tuple

start()
if called more than once on the same thread object
run()
join(): wait until the thread terminates
thread identifier: ident
is_alive


Lock():
loc is a synchronization primitive that is not owned by a thread when locked
locked and unlocked
lock:
acquire(), release()

acquire changes the state to locked and returns
release only be called in the locked state
##release the lock, wheh the lock is locked, reset it to unlocked return. if any other threads are blocked waiting for the lock to become unlocked, allow exactly one of them
##to proceed. 

##RLock
reentrant lock: synchronization primitive may be acquired multiple times by the same thread
the lock the lock, a thread calls acquire(); 
release()

###acquire(), release(): call the lock
##wait, notify, notifyAll
##wait(), notify(), notifyAll() method


##Producer-consumer situation
##consumer one item
cv.acquire()
while not an_item_is_available():
  cv.wait()
get_an_available_item()
cv.release()

##produce one item
cv.require()
make_an_item_available()
cv.notify()
cv.release()

threading.Condition
notify(n=1)
notifyAll()


##Event Objects
event object manages an internal flag that can be set to true with the set() method, reset to false with the clear() method
wait() method blocks until flag is true

threading.Event
is_set()
clear()
wait(): block until the internal flag is true

Timers:
Timer(): threads
start()
cancel()
interval the timer will wait before executing action

##计算总共的线程
threading.activeCount() - 1



总共为return的长度
不管threading call jige functions

generator: two generators
def mygenerator3(n, m):
  yield from mygenerator(n)
  yield from mygenerator2(n, m)
 print(list(mygenerator3(0, 10))
 
 
 original function calls mygenerator, mygenerator2 in sequence
 ###yield from
 itertools.chain
 def generator():
  for v in chain(generator2(), generator3()):
    yield v
    
 class Node:
    def __init__(self, value):
        self.left = []
        self.value = value
        self.right = []
     def iterate(self):
         for node in self.left:
            yield node.value
          yield self.value
          for node in self.right:
            yield node.value
    
 def main():
   root = Node(0)
   root.left = [Node(i) foer i in [1, 2, 3]]
   root.right = [Node(i) for i in [4, 5, 6]]
   for value in root.iterate():
    print(value)


i = root.iterate()
while True:
  try:
    it.send(None)
   except SopIteration:
    break

v = yield self.value

##refractoring over children:
def child_iterate(self, nodes):
  for node in nodes:
    input_value = yield node.value
    
 def node_iterate(self):
  yield from self.child_iterate(self.left)
  input_value = yield self.value
  yield from self.child_iterate(self.right)
  
  
  
  REST and Websockets
  sockets connected to each user and there is a time delay
  
  websockets:
  sockets being connected like each one having a radio
  send order into the radio and receive it the same time
  to groups 
  
  
  msgs: rest
 msg.  time for rest time for websockets
  10. 17.       13
  100. 112.     20
  500. 529.    68
  1000 1050.   115
  5000. 5183.  522
  10000 10547.   1019
  
  
  ###这个没法修理崩溃的bug
  RuntimeError: This event loop is already running
 close():
RuntimeError: Cannot close a running event loop

##solved:
import nest_asyncio
nest_asyncio.apply()

##break from generator
takewhile
[ x for x in takewhile( lambda x:sum(x)<20, gen() ) ]

import inspect
import foo

for name, obj in inspect.getmembers(foo):
    if inspect.isclass(obj):
        print obj


##跟class属性过不去了
no attribute---vsd itself
init start 

##two awaits & run_until_complete()

tab and indentation error is so annoying in visual studio code
##check dshift tab and tab again maybe cp error

check db's datatype 


##set time
time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))

##logging
DEBUG
INFO
WARNING
ERROR
CRITICAL

basicConfig(**kwargs)
only be called once
# level: root logger set to the specified severity level
# filename: this specifies the file
# filemode: filename is given, file is opened in this mode
# format 

Handlers


##websockets
event loop is running
sudo lsof -i:5000
kill


pass function into another function
##myfunction
def myfunc(anotherfunc, extraArgs):
    anotherfunc(*extraArgs)
To be more specific ... with various arguments ...

>>> def x(a,b):
...     print "param 1 %s param 2 %s"%(a,b)
...
>>> def y(z,t):
...     z(*t)
...
>>> y(x,("hello","manuel"))
param 1 hello param 2 manuel
>>>



##multithreading
thread not availale
_thread

##multiple threads within a process share same data space within the main thread
##share information 
##do not need much memory overhead

##beginning, execution and conclusion 

##kernel thread, and user thread
_thread & threading

_thread.start_new_thread(function, args[, kwards])

def fun(threadname, delay):
  c = 0
  while c<5:
    time.sleep(delay)
    c += 1
_thread.start_new_thread(print_time, ('thread1', 2, ))
##limited


Threading 

threading.activeCount()
threading.currentThread()
threading.enumerate(): currently active


#threading.Thread(target=run).start()
#_thread.start_new_thread(run, ())


run()
start()
join([time])
isAlive()
getName
setName


threading.Thread
run()
function(threadName, delay, counter)
threadName.exit()

thread.start()
thread.join()


synchronizing threads
acquire: force threads to run 
blocking: thread wait
set = 0: 0 value if lock cannot be acquired and 1 if lock was acquired; 1 wait

release()

threadLock = threading.Lock()
thread.start()
threads.append(thread)
for t in threads:
  t.join()
  
  
  
 ###channel data structure
 ###indentation of thread
 
 multithreadings priority queue
 get(): get removes and returns an item from the queue
 put():
 qsize()
 empty()
 full()
 
 
 ##创建一个新的queue控制size
 queueLock.acquire()
 if not workQueue.empty():
    data = q.get()
    queueLock.release()
  else:
    queueLock.release()
   
   
   
   ##make a list of threads
   ## make a list of names
   threadList
   nameList
   
  queueLock = threading.Lock()
  workQueue = Queue.Queue(10)
  threads = []
  threadID = 1
  
  ##create new threads
  for tName in threadList:
    thread = myThread(threadID, tName, workQueue)
    thread.start()
    threads.append(thread)
    threadID += 1
    
   ##fill the queue
   queueLock.acquire()
   for word in nameList:
      workQueue.put(word)
   queueLock.release()
    
    
 #wait for the queue to empty
 while not workQueue.empty():
    pass
    
   #Notify threads it's time to exit
   exitFlag = 1
   for t in threads:
    t.join()
    
    
 ###class variables
 https://stackoverflow.com/questions/12448414/this-constructor-takes-no-arguments-error-in-init
 __
##Test

class Test:
unittest.TestCase
assertEqual
assertNotEqual
assertTrue(x)
assertFalse(x)
assertIs(a, b)
assertIsNot(a, b)
assertisNone(x)
assertIsNotNone(x)
assertIn(a, b)
assertNotIn(a, b)
assertIsInstance(a, b):isinstance(a, b)
assertNotIsInstance(a, b)
assertRaises(TypeError)
assertRaisesRegexp(): regexp matches string representation
assertAlmostEqual(a, b)
assertNotAlmostEqual(a, b)
assertGreater(a, b)
assertGreaterEqual(a, b)
assertDictContainSubset(a, b): all keyvalue pairs in a exist in b

setUp()
tearDown()

unittest.TestSuite()
.addTest()
.addTest()

unittest.FunctionTestCase(test, setUp, tearDown)

@unittest.skip
@unittest.expectFailure


